{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwqfmxRa2WqHs+coqjuoQk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leof98/CS50/blob/main/TrabEntropia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trabalho matemática (presenças)**\n",
        "\n",
        "Nome: Leonardo Franco\n",
        "\n",
        "RA: 0051352321007\n",
        "\n"
      ],
      "metadata": {
        "id": "X94-5R-2dTU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        " Calcular Entropia\n",
        "\n",
        " Calcular Entropia Máxima\n",
        "\n",
        "H = - ∑ p(x)log(p(x))\n",
        "\n",
        "Hmax ​= − log2​(n​)"
      ],
      "metadata": {
        "id": "Y9NkSnKUeuT1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfXm0MAZByQP",
        "outputId": "41a267fd-903b-402f-ea82-5217dd679e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Values: ['animal' 'cool-macho' 'fluffy' 'food' 'name' 'nerdy-pop'\n",
            " 'password-related' 'rebellious-rude' 'simple-alphanumeric' 'sport']\n",
            "Counts: [ 29  79  44  11 183  30  15  11  61  37]\n",
            "Probabilities: [0.058 0.158 0.088 0.022 0.366 0.06  0.03  0.022 0.122 0.074]\n",
            "Term Values: [-0.23825259 -0.42059656 -0.30855903 -0.12113976 -0.53073091 -0.24353362\n",
            " -0.15176681 -0.12113976 -0.37027573 -0.27796849]\n",
            "\n",
            "Entropia: 2.7839632564166417\n",
            "Entropia máxima: 3.321928094887362\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# H = -sum(pk * log(pk))\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('passwords.csv')\n",
        "\n",
        "# Specify the column name\n",
        "column_name = 'category'\n",
        "\n",
        "# Extract the values from the specified column\n",
        "column_values = dataset[column_name].dropna().values\n",
        "\n",
        "# Calculate probabilities (p_k) for each unique value\n",
        "unique_values, counts = np.unique(column_values, return_counts=True)\n",
        "probs = counts / len(column_values)\n",
        "\n",
        "# Calculate the term p_k * log2(p_k) for each unique value\n",
        "term_values = probs * np.log2(probs)\n",
        "\n",
        "# Sum up the terms to get the final entropy value\n",
        "column_entropy = -np.sum(term_values)\n",
        "\n",
        "# Calculate the maximum entropy\n",
        "num_categories = len(unique_values)\n",
        "max_entropy = -np.log2(1 / num_categories)\n",
        "\n",
        "# Print intermediate steps for verification\n",
        "print(f\"Unique Values: {unique_values}\")\n",
        "print(f\"Counts: {counts}\")\n",
        "print(f\"Probabilities: {probs}\")\n",
        "print(f\"Term Values: {term_values}\\n\")\n",
        "\n",
        "# Print the final results\n",
        "print(f\"Entropia: {column_entropy}\")\n",
        "print(f\"Entropia máxima: {max_entropy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset utilizado: https://www.kaggle.com/datasets/sujaykapadnis/bad-passwords-never-use-them\n",
        "\n",
        "\n",
        "Coluna categórica escolhida: 'Category'\n",
        "\n",
        "Entropia ≈ 2.7839\n",
        "\n",
        "Entropia máxima ≈ 3.3219"
      ],
      "metadata": {
        "id": "eeX5tFzccB0d"
      }
    }
  ]
}